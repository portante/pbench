#!/usr/bin/env python3
# -*- mode: python -*-

"""pbench-tool-meister-start

Responsible for:

   1. Starting a redis server
   2. Loading up the tool group data for the target group into the redis server
   3. Starting the tool-data-sink process
   4. Starting all the local and remote tool meisters

When complete we leave running locally, a redis server and a tool data sink
process, and any local or remote tool meisters.

The pbench-tool-meister-stop will take care of (gracefully) stopping all of
these process, locally or remotely.
"""

import sys
import json
import os
import time
import errno

import podman
import redis
import logging

from config import conf
from redis import RedisError
config = conf["tool-meister"]
config_agent = conf["pbench-agent"]

logger = logging.getLogger(__file__)
logger.setLevel(logging.INFO)
sh = logging.StreamHandler()
sh.setLevel(logging.INFO)
shf = logging.Formatter('%(message)s')
sh.setFormatter(shf)
logger.addHandler(sh)


class ToolGroupException(Exception):
    pass


class ToolGroup(object):
    tg_prefix = "tools"

    def __init__(self, group):
        self.group = group
        _pbench_run = config_agent['pbench_run']
        _tg_dir = os.path.join(_pbench_run, f"{self.tg_prefix}-{self.group}")
        if not os.path.isdir(_tg_dir):
            raise ToolGroupException(f"bad tool group, {group}: directory {_tg_dir} does not exist")
        self.tg_dir = os.path.realpath(_tg_dir)

        try:
            with open(os.path.join(self.tg_dir, '__trigger__'), "r") as fp:
                _trigger = fp.read()
        except OSError as ex:
            if ex.errno != errno.ENOENT:
                raise
            self.trigger = None
        else:
            if len(_trigger) == 0:
                self.trigger = None
            else:
                self.trigger = _trigger

        # toolnames - Dict with tool name as the key, dictionary with host
        # names and parameters for each host
        self.toolnames = {}
        # hostnames - Dict with host name as the key, dictionary with tool
        # names and parameters for each tool
        self.hostnames = {}
        self.labels = {}
        for hdirent in os.listdir(self.tg_dir):
            if hdirent == '__trigger__':
                # Ignore handled above
                continue
            if not os.path.isdir(os.path.join(self.tg_dir, hdirent)):
                # Ignore wayward non-directory files
                continue
            # We assume this directory is a hostname.
            host = hdirent
            if host not in self.hostnames:
                self.hostnames[host] = {}
            for tdirent in os.listdir(os.path.join(self.tg_dir, host)):
                if tdirent == "__label__":
                    with open(os.path.join(self.tg_dir, host, tdirent)) as fp:
                        self.labels[host] = fp.read()
                    continue
                if tdirent.endswith("__noinstall__"):
                    # FIXME: ignore "noinstall" for now, tools are going to be
                    # in containers so this does not make sense going forward.
                    continue
                tool = tdirent
                with open(os.path.join(self.tg_dir, host, tool)) as fp:
                    tool_opts = fp.read()
                if tool not in self.toolnames:
                    self.toolnames[tool] = {}
                self.toolnames[tool][host] = tool_opts

    def get_tools(self, host):
        """Given a target host, return a dictionary with the list of tool names
        as keys, and the values being their options for that host.
        """
        tools = dict()
        for tool, opts in self.toolnames.items():
            tools[tool] = opts[host]
        return tools


def wait_for_subs(redis_server, chan, expected_tms, _logger):
    """Wait for the data sink and the proper number of TMs to register, and
    when they are all registered, then record them in the "tm-pids" key.
    """
    pids = dict()
    have_ds = False
    num_tms = 0
    for payload in chan:
        try:
            json_str = payload['data'].decode('utf-8')
        except KeyError:
            _logger.error("data payload missing in message")
            continue
        except UnicodeDecodeError:
            _logger.warning("data payload in message not UTF-8")
            continue
        _logger.debug(f"channel payload, '{json_str}'")
        try:
            data = json.loads(json_str)
        except json.JSONDecodeError:
            _logger.warning(f"data payload in message not JSON, '{json_str}'")
            continue
        # We expect the payload to look like:
        #   { "kind": "<ds|tm>",
        #     "hostname": "<hostname>",
        #     "pid": "<pid>"
        #   }
        # Where 'kind' is either 'ds' (data-sink) or 'tm' (tool-meister),
        # 'hostname' is the host name on which that entity is running, and
        # 'pid' is that entity's PID on that host.
        try:
            new_data = dict(
                kind=data['kind'],
                hostname=data['hostname'],
                pid=data['pid']
            )
        except KeyError:
            _logger.warning(f"unrecognized data payload in message, '{data}'")
            continue
        else:
            if new_data['kind'] == 'ds':
                pids['ds'] = new_data
                have_ds = True
            elif new_data['kind'] == 'tm':
                if 'tm' not in pids:
                    pids['tm'] = []
                pids['tm'].append(new_data)
                num_tms += 1
            else:
                _logger.warning(f"unrecognized 'kind', in data payload '{data}'")
                continue
        if have_ds and num_tms == expected_tms:
            break
    # Record our collected pids.
    redis_server.set("tm-pids", json.dumps(pids))


def main(argv):
    """
    Main program for the tool meister start.
    """
    redis_port = config["redis_port"]
    channel = config["channel"]

    try:
        group = argv[1]
    except IndexError:
        group = "default"

    # 1. Load the tool group data given the tool group argument
    try:
        tool_group = ToolGroup(group)
    except ToolGroupException:
        logger.exception("failed to load tool group data")
        return 1

    try:
        benchmark_run_dir = os.environ['benchmark_run_dir']
        full_hostname = os.environ['full_hostname']
    except KeyError:
        logger.exception("failed to fetch parameters from the environment")
        return 1
    else:
        tm_dir = os.path.join(benchmark_run_dir, "tm")
        try:
            if not os.path.exists(tm_dir):
                os.mkdir(tm_dir)
            os.chdir(tm_dir)
        except OSError:
            logger.exception("failed to create the local tool meister directory")
            return 1
    if os.environ.get('_PBENCH_BENCH_TESTS'):
        hostnames = "localhost"
    else:
        hostnames = f"localhost {full_hostname}"
    params = {
        'hostnames': hostnames,
        'tm_dir': tm_dir,
        'redis_port': redis_port
    }

    try:
        # Start the Redis Server itself
        with podman.Client(f"unix:/run/podman/io.podman") as client:
            image_id = client.images.pull("redis:latest")
            img = client.images.get(image_id)
            container = img.create(
                detach=True,
                rm=True,
                name="tm-redis",
                publish=[f"{redis_port}:{redis_port}"],
            )
            container.start()
    except Exception:
        logger.exception(f"Unable to create redis container.")
        return 1

    try:
        redis_server = redis.Redis(host="localhost", port=redis_port, db=0)
    except RedisError as e:
        container.stop()
        logger.error(f"Unable to connect to redis server, localhost:{redis_port}: {e}")
        return 1
    else:
        pubsub = redis_server.pubsub()

    try:
        timeout = time.time() + 60
        started_channel = f"{channel}-start"
        redis_connection_state = "connecting"
        while redis_connection_state == "connecting":
            try:
                pubsub.subscribe(started_channel)
            except redis.exceptions.ConnectionError:
                if time.time() > timeout:
                    raise
            else:
                redis_connection_state = "connected"
        chan = pubsub.listen()
        # Pull off first message which is an acknowledgement we have
        # successfully subscribed.
        resp = next(chan)
        assert resp['type'] == 'subscribe', f"bad type: {resp}"
        assert resp['pattern'] is None, f"bad pattern: {resp}"
        assert resp['channel'].decode('utf-8') == started_channel, f"bad channel: {resp}"
        assert resp['data'] == 1, f"bad data: {resp}"
    except Exception:
        logger.exception("Unable to setup start channel")
        return 1

    # 3. Start the tool-data-sink process
    #   - leave a PID file for the tool data sink process
    #   - FIXME: use podman to start a tool-data-sink container
    tds_param_key = f"tds-{group}"
    tds = dict(channel=channel, benchmark_run_dir=benchmark_run_dir)
    try:
        redis_server.set(tds_param_key, json.dumps(tds))
    except RedisError:
        logger.exception("failed to create tool-data-sink parameter key in redis server")
        container.stop()
        return 1
    data_sink = "pbench-tool-data-sink"
    data_sink_path = os.path.join(os.path.dirname(argv[0]), data_sink)
    logger.debug("starting tool data sink")
    try:
        ret_code = os.spawnl(os.P_WAIT, data_sink_path, data_sink, "localhost", str(redis_port), tds_param_key)
    except (TypeError, ValueError, OSError):
        logger.exception("failed to create pbench data sink, daemonized")
        return 1
    else:
        if ret_code != 0:
            logger.error("failed to create pbench data sink, daemonized;"
                         " return code: %d", ret_code)
            return 1

    # 4. Start all the local and remote tool meister processes
    #   - leave a PID file on each local/remote host
    #   - FIXME: use podman on the remote hosts to start a tool meister
    #            container
    failures = 0
    successes = 0
    tool_meister_cmd = "pbench-tool-meister"
    tool_meister_cmd_path = os.path.join(os.path.dirname(argv[0]),
                                         tool_meister_cmd)
    ssh_cmd = "ssh"
    args = [ssh_cmd, "<host replace me>", tool_meister_cmd, full_hostname,
            redis_port, "<tm param key>"]
    ssh_pids = []
    for host in tool_group.hostnames.keys():
        tools = tool_group.get_tools(host)
        tm = dict(hostname=host, channel=channel, group=group,
                  benchmark_run_dir=benchmark_run_dir, tools=tools)
        tm_param_key = "tm-{}-{}".format(group, host)
        try:
            redis_server.set(tm_param_key, json.dumps(tm))
        except RedisError:
            logger.exception("failed to create tool-data-sink parameter key"
                             " in redis server")
            container.stop()
            return 1
        if host == full_hostname:
            logger.debug("starting localhost tool meister")
            try:
                ret_code = os.spawnl(
                    os.P_WAIT,
                    tool_meister_cmd_path,
                    tool_meister_cmd,
                    "localhost",
                    str(redis_port),
                    tm_param_key
                )
            except OSError:
                logger.exception("failed to create pbench tool meister, daemonized")
                failures += 1
            else:
                if ret_code == 0:
                    successes += 1
                else:
                    logger.error(f"failed to create pbench tool meister, daemonized; return code: {ret_code}")
                    failures += 1

            continue
        args[1] = host
        args[5] = tm_param_key
        logger.debug("starting remote tool meister")
        try:
            pid = os.spawnv(os.P_NOWAIT, ssh_cmd, args)
        except OSError:
            logger.exception("failed to create a tool meister instance for"
                             " host %s", host)
            failures += 1
        else:
            ssh_pids.append((pid, host))
            successes += 1
    # Wait for all the SSH pids to complete.
    for pid, host in ssh_pids:
        try:
            os.waitpid(pid, 0)
        except OSError:
            logger.exception("failed to create a tool meister instance for"
                             " host %s", host)
            failures += 1

    # If any successes, then we need to wait for them to show up as
    # subscribers.
    logger.debug("waiting for subs")
    wait_for_subs(redis_server, chan, successes, logger)

    # For any failures, just terminate early.
    if failures > 0:
        logger.info("terminating localhost:%d due to failures", redis_port)
        terminate_msg = dict(state="terminate", iteration=None)
        try:
            ret = redis_server.publish(channel, json.dumps(terminate_msg))
        except RedisError:
            logger.exception("Failed to publish terminate message")
        else:
            logger.debug("publish() = %r", ret)
        container.stop()

    return 1 if failures > 0 else 0


if __name__ == '__main__':
    status = main(sys.argv)
    sys.exit(status)
